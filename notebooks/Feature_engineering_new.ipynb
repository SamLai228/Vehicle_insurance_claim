{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Import Datasets\n",
    "# this dataset has not dropped any features but encoded\n",
    "df = pd.read_csv('../data/processed/data_cleaned_v2.csv') \n",
    "# import 原始資料方便特徵創造\n",
    "df_raw = pd.read_csv('/Users/samlai/Documents/Vehicle_insurance_claim_project/data/raw/fraud_oracle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將特徵分組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保險人特徵\n",
    "policyholder_feature = [\n",
    "    'Sex', 'Age', 'DriverRating_2', 'DriverRating_3', 'DriverRating_4',\n",
    "    'AgeOfPolicyHolder_18 to 20', 'AgeOfPolicyHolder_21 to 25',\n",
    "    'AgeOfPolicyHolder_26 to 30', 'AgeOfPolicyHolder_31 to 35', \n",
    "    'AgeOfPolicyHolder_36 to 40', 'AgeOfPolicyHolder_41 to 50',\n",
    "    'AgeOfPolicyHolder_51 to 65', 'AgeOfPolicyHolder_over 65',\n",
    "    'AddressChange_Claim_2 to 3 years', 'AddressChange_Claim_4 to 8 years',\n",
    "    'AddressChange_Claim_no change', 'AddressChange_Claim_under 6 months', 'NumberOfCars_2 vehicles',\n",
    "    'NumberOfCars_3 to 4', 'NumberOfCars_5 to 8', 'NumberOfCars_more than 8',\n",
    "    'PastNumberOfClaims', 'MaritalStatus_Married', 'MaritalStatus_Single',\n",
    "    'MaritalStatus_Widow'\n",
    "]\n",
    "\n",
    "# 車禍事件特徵 \n",
    "accident_feature = [\n",
    "    'AccidentArea', 'Fault', 'PoliceReportFiled', 'NumberOfSuppliments',\n",
    "    'Days_Policy_Accident_more than 30', 'Days_Policy_Accident_15 to 30',\n",
    "    'Days_Policy_Accident_8 to 15', 'Days_Policy_Accident_none',\n",
    "    'Days_Policy_Claim_8 to 15', 'Days_Policy_Claim_more than 30',\n",
    "    'Days_Policy_Claim_none', 'BasePolicy_Collision', 'BasePolicy_Liability',\n",
    "    'Deductible_400', 'Deductible_500', 'Deductible_700',\n",
    "    'PolicyType_Sedan - Collision', 'PolicyType_Sedan - Liability',\n",
    "    'PolicyType_Sport - Collision', 'PolicyType_Sport - All Perils',\n",
    "    'PolicyType_Sport - Liability', 'PolicyType_Utility - All Perils',\n",
    "    'PolicyType_Utility - Collision', 'PolicyType_Utility - Liability', 'WitnessPresent'\n",
    "]\n",
    "\n",
    "# 車輛特徵\n",
    "vehicle_feature = [\n",
    "    'AgeOfVehicle', 'VehiclePrice_30000 to 39000',\n",
    "    'VehiclePrice_40000 to 59000', 'VehiclePrice_less than 20000', 'VehiclePrice_60000 to 69000',\n",
    "    'VehiclePrice_more than 69000', 'Make_Chevrolet', 'Make_Ford',\n",
    "    'Make_Honda', 'Make_Mazda', 'Make_Pontiac', 'Make_Toyota', 'Make_VW',\n",
    "    'Make_BMW', 'Make_Dodge', 'Make_Ferrari', 'Make_Jaguar', 'Make_Lexus',\n",
    "    'Make_Mecedes', 'Make_Mercury', 'Make_Nisson', 'Make_Porche', 'Make_Saab',\n",
    "    'Make_Saturn', 'VehicleCategory_Sport', 'VehicleCategory_Utility'\n",
    "]\n",
    "\n",
    "# 時間特徵\n",
    "time_feature = [\n",
    "    'Month_Aug', 'Month_Dec', 'Month_Feb', 'Month_Jan', 'Month_Jul',\n",
    "    'Month_Jun', 'Month_Mar', 'Month_May', 'Month_Nov', 'Month_Oct',\n",
    "    'Month_Sep', 'WeekOfMonth_2', 'WeekOfMonth_3', 'WeekOfMonth_4',\n",
    "    'WeekOfMonth_5', 'DayOfWeek_Monday', 'DayOfWeek_Saturday',\n",
    "    'DayOfWeek_Sunday', 'DayOfWeek_Thursday', 'DayOfWeek_Tuesday',\n",
    "    'DayOfWeek_Wednesday', 'Year_1995', 'Year_1996',\n",
    "    'DayOfWeekClaimed_Friday', 'DayOfWeekClaimed_Monday', 'DayOfWeekClaimed_Saturday',\n",
    "    'DayOfWeekClaimed_Sunday', 'DayOfWeekClaimed_Thursday', 'DayOfWeekClaimed_Tuesday',\n",
    "    'DayOfWeekClaimed_Wednesday', 'MonthClaimed_Apr', 'MonthClaimed_Aug',\n",
    "    'MonthClaimed_Dec', 'MonthClaimed_Feb', 'MonthClaimed_Jan', 'MonthClaimed_Jul',\n",
    "    'MonthClaimed_Jun', 'MonthClaimed_Mar', 'MonthClaimed_May', 'MonthClaimed_Nov',\n",
    "    'MonthClaimed_Oct', 'MonthClaimed_Sep', 'WeekOfMonthClaimed_2',\n",
    "    'WeekOfMonthClaimed_3', 'WeekOfMonthClaimed_4', 'WeekOfMonthClaimed_5'\n",
    "]\n",
    "\n",
    "# 其他特徵\n",
    "other_feature = [\n",
    "    'AgentType', 'RepNumber_2', 'RepNumber_3', 'RepNumber_4', 'RepNumber_5',\n",
    "    'RepNumber_6', 'RepNumber_7', 'RepNumber_8', 'RepNumber_9',\n",
    "    'RepNumber_10', 'RepNumber_11', 'RepNumber_12', 'RepNumber_13',\n",
    "    'RepNumber_14', 'RepNumber_15', 'RepNumber_16'\n",
    "]\n",
    "\n",
    "Target = ['FraudFound_P']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未分組的特徵:\n",
      "FraudFound_P\n"
     ]
    }
   ],
   "source": [
    "# 檢查是否有特徵未被分組\n",
    "all_grouped_features = policyholder_feature + accident_feature + vehicle_feature + time_feature + other_feature\n",
    "all_features = df.columns.tolist()\n",
    "\n",
    "\n",
    "ungrouped_features = [f for f in all_features if f not in all_grouped_features]\n",
    "if ungrouped_features:\n",
    "    print(\"未分組的特徵:\")\n",
    "    for f in ungrouped_features:\n",
    "        print(f)\n",
    "else:\n",
    "    print(\"所有特徵都已被分組\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policyholder = df[policyholder_feature]\n",
    "df_accident = df[accident_feature]\n",
    "df_vehicle = df[vehicle_feature]\n",
    "df_time = df[time_feature]\n",
    "df_other = df[other_feature]\n",
    "df_target = df[Target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Function to evaluate created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score\n",
    "def get_test_metrics(y_test, y_pred, y_prob):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'AUC: {auc:.4f}')\n",
    "\n",
    "    # Calculate and print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def model_test(df_policyholder, df_accident, df_vehicle, df_time, df_other, df_target):\n",
    "    df_new = pd.concat([df_policyholder, df_accident, df_vehicle, df_time, df_other, df_target], axis=1)\n",
    "    X = df_new.drop(columns = ['FraudFound_P'])\n",
    "    y = df_new['FraudFound_P']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "    # use Random Undersampling\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_rus, y_train_rus)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    get_test_metrics(y_test, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def cv_evaluation(df_policyholder, df_accident, df_vehicle, df_time, df_other, df_target):\n",
    "    # 合併所有特徵\n",
    "    df_new = pd.concat([df_policyholder, df_accident, df_vehicle, df_time, df_other, df_target], axis=1)\n",
    "    X = df_new.drop(columns=['FraudFound_P'])\n",
    "    y = df_new['FraudFound_P']\n",
    "    \n",
    "    # 定義 5 折交叉驗證\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # 儲存每折的分數\n",
    "    cv_scores = []\n",
    "    \n",
    "    # 進行交叉驗證\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        # 分割數據\n",
    "        X_train_fold = X.iloc[train_idx]\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        X_val_fold = X.iloc[val_idx]\n",
    "        y_val_fold = y.iloc[val_idx]\n",
    "        \n",
    "        # 下採樣\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_train_rus, y_train_rus = rus.fit_resample(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # 訓練模型\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_rus, y_train_rus)\n",
    "        \n",
    "        # 預測\n",
    "        y_val_pred = model.predict(X_val_fold)\n",
    "        y_val_prob = model.predict_proba(X_val_fold)[:, 1]\n",
    "        \n",
    "        # 計算分數\n",
    "        scores = {\n",
    "            'accuracy': accuracy_score(y_val_fold, y_val_pred),\n",
    "            'precision': precision_score(y_val_fold, y_val_pred),\n",
    "            'recall': recall_score(y_val_fold, y_val_pred),\n",
    "            'f1': f1_score(y_val_fold, y_val_pred),\n",
    "            'auc': roc_auc_score(y_val_fold, y_val_prob)\n",
    "        }\n",
    "        cv_scores.append(scores)\n",
    "    \n",
    "    # 計算平均分數\n",
    "    print(\"Average CV scores:\")\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc']:\n",
    "        mean_score = np.mean([s[metric] for s in cv_scores])\n",
    "        print(f\"{metric}: {mean_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 將Age分群 (結論：已有 'AgeOfPolicyHolder'，刪除Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV scores:\n",
      "accuracy: 0.6553\n",
      "precision: 0.1369\n",
      "recall: 0.8960\n",
      "f1: 0.2375\n",
      "auc: 0.8157\n"
     ]
    }
   ],
   "source": [
    "df_policyholder_dropAge = df_policyholder.drop(columns = 'Age')\n",
    "cv_evaluation(df_policyholder_dropAge, df_accident, df_vehicle, df_time, df_other, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除Age後，成效有些為提升，因此將Age移除\n",
    "df_policyholder = df_policyholder.drop(columns = 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.創造高風險車子品牌標籤特徵 (結論：保留新建的高風險特徵，移除所有Brand Make特徵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/klmxbc1d2x58bny86xqxsjqc0000gn/T/ipykernel_52308/1558674046.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_vehicle['HighRisk_brand'] = ((df_vehicle[high_risk_makes].any(axis=1)) |\n"
     ]
    }
   ],
   "source": [
    "# Create HighRisk_brand feature based on specific makes\n",
    "# Mecedes, BMW, Saab, Saturn, BMW, Ford, Mercury 這些為高風險品牌\n",
    "# Accurca 是One-hot Encoding後的基準類別，其他 Make features若皆為 0 就是Accurca\n",
    "high_risk_makes = ['Make_Mecedes', 'Make_Saab', 'Make_Saturn', 'Make_BMW', 'Make_Ford', 'Make_Mercury']\n",
    "\n",
    "# Get all make columns\n",
    "all_makes = ['Make_Chevrolet', 'Make_Ford', 'Make_Honda', 'Make_Mazda', 'Make_Pontiac', \n",
    "            'Make_Toyota', 'Make_VW', 'Make_BMW', 'Make_Dodge', 'Make_Ferrari', \n",
    "            'Make_Jaguar', 'Make_Lexus', 'Make_Mecedes', 'Make_Mercury', 'Make_Nisson',\n",
    "            'Make_Porche', 'Make_Saab', 'Make_Saturn']\n",
    "\n",
    "# Create HighRisk_brand feature\n",
    "df_vehicle['HighRisk_brand'] = ((df_vehicle[high_risk_makes].any(axis=1)) | \n",
    "                               (df_vehicle[all_makes].sum(axis=1) == 0)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV scores:\n",
      "accuracy: 0.6548\n",
      "precision: 0.1370\n",
      "recall: 0.8981\n",
      "f1: 0.2377\n",
      "auc: 0.8171\n"
     ]
    }
   ],
   "source": [
    "cv_evaluation(df_policyholder, df_accident, df_vehicle, df_time, df_other, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV scores:\n",
      "accuracy: 0.6543\n",
      "precision: 0.1353\n",
      "recall: 0.8851\n",
      "f1: 0.2347\n",
      "auc: 0.8178\n"
     ]
    }
   ],
   "source": [
    "# 試著把Make相關features都刪掉，因為有HighRisk_brand了\n",
    "df_vehicle_withoutMake = df_vehicle.drop(columns = all_makes)\n",
    "cv_evaluation(df_policyholder, df_accident, df_vehicle_withoutMake, df_time, df_other, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將18個Brand Make相關feature都刪除後，recall跟F1 score反而有些為提升，表示一個HighRisk_brand就可以提供足夠資訊\n",
    "# 更新df_vehicle，移除 Brand Make 相關欄位\n",
    "df_vehicle = df_vehicle.drop(columns = all_makes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.移除PolicyType 或BasePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV scores:\n",
      "accuracy: 0.6569\n",
      "precision: 0.1354\n",
      "recall: 0.8776\n",
      "f1: 0.2346\n",
      "auc: 0.8172\n"
     ]
    }
   ],
   "source": [
    "# PolicyType Column為Based Policy與Vehicle Category的組合，移除PolictType測試\n",
    "# Get all PolicyType columns\n",
    "policy_type_cols = [col for col in df_accident.columns if col.startswith('PolicyType')]\n",
    "\n",
    "# Remove PolicyType columns from df_accident\n",
    "df_accident_dropPolicyType = df_accident.drop(columns=policy_type_cols)\n",
    "\n",
    "cv_evaluation(df_policyholder, df_accident_dropPolicyType, df_vehicle, df_time, df_other, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV scores:\n",
      "accuracy: 0.6690\n",
      "precision: 0.1398\n",
      "recall: 0.8765\n",
      "f1: 0.2410\n",
      "auc: 0.8231\n"
     ]
    }
   ],
   "source": [
    "# 移除Based Policy與Vehicle Category\n",
    "# Get all Based Policy columns\n",
    "BasePolicy_cols = [col for col in df_accident.columns if col.startswith('BasePolicy')]\n",
    "df_accident_dropBasePolicy = df_accident.drop(columns=BasePolicy_cols)\n",
    "\n",
    "VehicleCategory_col = [col for col in df_vehicle.columns if col.startswith('VehicleCategory')]\n",
    "df_vehicle_dropCategory = df_vehicle.drop(columns=VehicleCategory_col)\n",
    "\n",
    "cv_evaluation(df_policyholder, df_accident_dropBasePolicy, df_vehicle_dropCategory, df_time, df_other, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除Based Policy與Vehicle Category在交叉驗證瞟線上較好\n",
    "# 更新df_accident與df_vehicle\n",
    "df_accident = df_accident.drop(columns=BasePolicy_cols)\n",
    "df_vehicle = df_vehicle.drop(columns=VehicleCategory_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.'Days_Policy_Accident' and 'Days_Policy_Claim' Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Days_Policy_Accident_morethan30 feature\n",
    "days_policy_accident_col = [col for col in df_accident.columns if col.startswith('Days_Policy_Accident')]\n",
    "df_accident = df_accident.drop(columns=days_policy_accident_col)\n",
    "df_accident['Days_Policy_Accident_morethan30'] = (df_raw['Days_Policy_Accident'] == 'more than 30').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Days_Policy_Claim_morethan30 feature\n",
    "days_policy_claim_col = [col for col in df_accident.columns if col.startswith('Days_Policy_Claim')]\n",
    "df_accident = df_accident.drop(columns=days_policy_claim_col)\n",
    "df_accident['Days_Policy_Claim_morethan30'] = (df_raw['Days_Policy_Claim'] == 'more than 30').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV scores:\n",
      "accuracy: 0.6682\n",
      "precision: 0.1383\n",
      "recall: 0.8678\n",
      "f1: 0.2386\n",
      "auc: 0.8200\n"
     ]
    }
   ],
   "source": [
    "cv_evaluation(df_policyholder, df_accident, df_vehicle, df_time, df_other, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV scores:\n",
      "accuracy: 0.6617\n",
      "precision: 0.1342\n",
      "recall: 0.8516\n",
      "f1: 0.2318\n",
      "auc: 0.8221\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Average CV scores:\n",
      "accuracy: 0.6620\n",
      "precision: 0.1360\n",
      "recall: 0.8668\n",
      "f1: 0.2350\n",
      "auc: 0.8180\n"
     ]
    }
   ],
   "source": [
    "# 因為兩個特徵非常相似，試著刪掉其中一個\n",
    "df_accident_dropAccident = df_accident.drop(columns = 'Days_Policy_Accident_morethan30')\n",
    "cv_evaluation(df_policyholder, df_accident_dropAccident, df_vehicle, df_time, df_other, df_target)\n",
    "print('-'*100)\n",
    "df_accident_dropClaim = df_accident.drop(columns = 'Days_Policy_Claim_morethan30')\n",
    "cv_evaluation(df_policyholder, df_accident_dropClaim, df_vehicle, df_time, df_other, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between 2 variables: 0.6347\n"
     ]
    }
   ],
   "source": [
    "# Calculate correlation between Days_Policy_Accident_morethan30 and Days_Policy_Claim_morethan30\n",
    "correlation = df_accident['Days_Policy_Accident_morethan30'].corr(df_accident['Days_Policy_Claim_morethan30'])\n",
    "print(f\"Correlation between 2 variables: {correlation:.4f}\")\n",
    "\n",
    "# drop 'Days_Policy_Claim_morethan30'\n",
    "df_accident = df_accident.drop(columns = 'Days_Policy_Claim_morethan30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 合併AddressChange_Claim, Number of Cars中的少數別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將AddressChange_Claim中的'under 6 months', '1 year', '2 to 3 years'合併為 'under 3 years'\n",
    "# 但由於只剩 'under 3 years', 'no change', '4 to 8 years'三個選項，\n",
    "# 因此透過'no change', '4 to 8 years'就可以推斷出'under 3 years'欄位的值，\n",
    "# 不需要創造 'AddressChange_Claim_under 3 years'欄位\n",
    "df_policyholder = df_policyholder.drop(columns = ['AddressChange_Claim_2 to 3 years', 'AddressChange_Claim_under 6 months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policyholder['More than 1 car'] = (df_raw['NumberOfCars'] != '1 vehicle').astype(int)\n",
    "NumberOfCars_col = [col for col in df_policyholder.columns if col.startswith('NumberOfCars')]\n",
    "df_policyholder = df_policyholder.drop(columns=NumberOfCars_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
