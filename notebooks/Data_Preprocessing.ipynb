{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packsges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('/Users/samlai/Documents/Vehicle_insurance_claim_project/data/raw/fraud_oracle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15420 entries, 0 to 15419\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Month                 15420 non-null  object\n",
      " 1   WeekOfMonth           15420 non-null  int64 \n",
      " 2   DayOfWeek             15420 non-null  object\n",
      " 3   Make                  15420 non-null  object\n",
      " 4   AccidentArea          15420 non-null  object\n",
      " 5   DayOfWeekClaimed      15420 non-null  object\n",
      " 6   MonthClaimed          15420 non-null  object\n",
      " 7   WeekOfMonthClaimed    15420 non-null  int64 \n",
      " 8   Sex                   15420 non-null  object\n",
      " 9   MaritalStatus         15420 non-null  object\n",
      " 10  Age                   15420 non-null  int64 \n",
      " 11  Fault                 15420 non-null  object\n",
      " 12  PolicyType            15420 non-null  object\n",
      " 13  VehicleCategory       15420 non-null  object\n",
      " 14  VehiclePrice          15420 non-null  object\n",
      " 15  FraudFound_P          15420 non-null  int64 \n",
      " 16  PolicyNumber          15420 non-null  int64 \n",
      " 17  RepNumber             15420 non-null  int64 \n",
      " 18  Deductible            15420 non-null  int64 \n",
      " 19  DriverRating          15420 non-null  int64 \n",
      " 20  Days_Policy_Accident  15420 non-null  object\n",
      " 21  Days_Policy_Claim     15420 non-null  object\n",
      " 22  PastNumberOfClaims    15420 non-null  object\n",
      " 23  AgeOfVehicle          15420 non-null  object\n",
      " 24  AgeOfPolicyHolder     15420 non-null  object\n",
      " 25  PoliceReportFiled     15420 non-null  object\n",
      " 26  WitnessPresent        15420 non-null  object\n",
      " 27  AgentType             15420 non-null  object\n",
      " 28  NumberOfSuppliments   15420 non-null  object\n",
      " 29  AddressChange_Claim   15420 non-null  object\n",
      " 30  NumberOfCars          15420 non-null  object\n",
      " 31  Year                  15420 non-null  int64 \n",
      " 32  BasePolicy            15420 non-null  object\n",
      "dtypes: int64(9), object(24)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop useless column and change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID Column\n",
    "df_cleaned = df_cleaned.drop(columns = ['PolicyNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RepNumber should be categorical\n",
    "# WeekOfMonth and WeekOfMonthClaimed should be categorical\n",
    "# Deductible should be categorical\n",
    "# Year should be categorical\n",
    "# DriverRating should be categorical\n",
    "df_cleaned['RepNumber'] = df_cleaned['RepNumber'].astype('category')\n",
    "df_cleaned['WeekOfMonth'] = df_cleaned['WeekOfMonth'].astype('category')\n",
    "df_cleaned['WeekOfMonthClaimed'] = df_cleaned['WeekOfMonthClaimed'].astype('category')\n",
    "df_cleaned['Deductible'] = df_cleaned['Deductible'].astype('category')\n",
    "df_cleaned['Year'] = df_cleaned['Year'].astype('category')\n",
    "df_cleaned['DriverRating'] = df_cleaned['DriverRating'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Binary Variables (AccidentArea, Sex, Fault, PoliceReportFiled, WitnessPresent, AgentType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "binary_columns = [col for col in df_cleaned.columns if len(df_cleaned[col].unique()) == 2 and\n",
    "                  col != 'FraudFound_P']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in binary_columns:\n",
    "    df_cleaned[col] = le.fit_transform(df_cleaned[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Ordinal Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將有順序的類別變數Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values in DriverRating: [1, 4, 3, 2]\n",
      "Categories (4, int64): [1, 2, 3, 4]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Unique Values in PastNumberOfClaims: ['none' '1' '2 to 4' 'more than 4']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Unique Values in AgeOfVehicle: ['3 years' '6 years' '7 years' 'more than 7' '5 years' 'new' '4 years'\n",
      " '2 years']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Unique Values in NumberOfSuppliments: ['none' 'more than 5' '3 to 5' '1 to 2']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for col in ['DriverRating', 'PastNumberOfClaims', 'AgeOfVehicle', 'NumberOfSuppliments']:\n",
    "    print(f'Unique Values in {col}: {df_cleaned[col].unique()}')\n",
    "    print('-'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DriverRating is already numerical, don't need to encode\n",
    "PastNumberClaims_label = {'none': 0, '1': 1, '2 to 4': 2, 'more than 4': 3}\n",
    "AgeOfVehicle_label = {'new': 0, '2 years': 1, '3 years': 2, '4 years': 3, '5 years': 4,\n",
    "                      '6 years': 5, '7 years': 6, 'more than 7': 7}\n",
    "NumberOfSuppliments_label = {'none': 0, '1 to 2': 1, '3 to 5': 2, 'more than 5': 3}\n",
    "\n",
    "df_cleaned['PastNumberOfClaims'] = df_cleaned['PastNumberOfClaims'].map(PastNumberClaims_label)\n",
    "df_cleaned['AgeOfVehicle'] = df_cleaned['AgeOfVehicle'].map(AgeOfVehicle_label)\n",
    "df_cleaned['NumberOfSuppliments'] = df_cleaned['NumberOfSuppliments'].map(NumberOfSuppliments_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Nominal Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA中發現VehiclePrice, Deductible, Age of Policy Holder, Number of Cars, AddressChangeClaim與與詐欺率之間不是簡單的線性關係，因此用One-Hot encoding較適合（可以獨立學習每個類別）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15420, 139)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode Nominal Variables\n",
    "df_cleaned_v2 = pd.get_dummies(df_cleaned, drop_first = True)\n",
    "df_cleaned_v2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop similar features first, then encode Nominal Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_v3 = df_cleaned.drop(columns = ['DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15420, 116)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_v3 = pd.get_dummies(df_cleaned_v3, drop_first = True)\n",
    "df_cleaned_v3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute strange values in Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_v4 = df_cleaned_v3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cleaned_v4[df_cleaned_v4['Age'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_v4['Age'] = df_cleaned_v4['Age'].apply(lambda x: np.nan if x == 0 else x)\n",
    "\n",
    "# Initialize Random Forest Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_imputer = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Get features for imputation (exclude Age column)\n",
    "features = df_cleaned_v4.drop('Age', axis=1).columns\n",
    "X = df_cleaned_v4[features]\n",
    "y = df_cleaned_v4['Age']\n",
    "\n",
    "# Fit imputer on non-null values\n",
    "mask_not_null = ~df_cleaned_v4['Age'].isna()\n",
    "rf_imputer.fit(X[mask_not_null], y[mask_not_null])\n",
    "\n",
    "# Predict missing values\n",
    "mask_null = df_cleaned_v4['Age'].isna()\n",
    "df_cleaned_v4.loc[mask_null, 'Age'] = rf_imputer.predict(X[mask_null])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Variance Threshold to select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_v5 = df_cleaned_v4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15420, 86)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X = df_cleaned_v5.drop(columns = 'FraudFound_P')\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.01)\n",
    "X_selected = selector.fit_transform(X)\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected features\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "# create a dataframe only with selected features\n",
    "df_cleaned_v5 = df_cleaned_v5[selected_features]\n",
    "\n",
    "# Add back target variable\n",
    "df_cleaned_v5['FraudFound_P'] = df_cleaned_v4['FraudFound_P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SMOTE first, then use Variancethreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudFound_P\n",
       "0    11598\n",
       "1    11598\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X = df_cleaned_v5.drop(columns = 'FraudFound_P')\n",
    "y = df_cleaned_v5['FraudFound_P']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23196, 84)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.01)\n",
    "X_selected = selector.fit_transform(X_train_smote)\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected features\n",
    "selected_features = X_train_smote.columns[selector.get_support()]\n",
    "\n",
    "# create a dataframe only with selected features\n",
    "X_train_smote_selected = X_train_smote[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Add back y_train_smote and y_test\n",
    "df_train_v6 = X_train_smote_selected.copy()\n",
    "df_train_v6['FraudFound_P'] = y_train_smote\n",
    "\n",
    "df_test_v6 = X_test_selected.copy()\n",
    "df_test_v6['FraudFound_P'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned_v2 --> without any feature engineering, without dropping any columns\n",
    "df_cleaned_v2.to_csv('../data/processed/data_cleaned_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cleaned_v3 --> without any feature engineering, but drop similar features\n",
    "df_cleaned_v3.to_csv('../data/processed/data_cleaned_v3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cleaned_v4 --> without any feature engineering, but drop similar features and correct strange values in Age\n",
    "df_cleaned_v4.to_csv('../data/processed/data_cleaned_v4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cleaned_v5 --> without any feature engineering, from v4 but selected features by Variancethreshold\n",
    "df_cleaned_v5.to_csv('../data/processed/data_cleaned_v5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_v6, df_test_v6 --> use smote first then Variancethreshold\n",
    "df_train_v6.to_csv('../data/processed/df_train_v6.csv', index = False)\n",
    "df_test_v6.to_csv('../data/processed/df_test_v6.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
